# Data_Mining

用于2019年秋季哈尔滨工业大学数据挖掘课程

## 课程内容补充参考

### 在线广告问题、推荐系统相关、社会图挖掘相关补充

这一部分主要内容来自[Mining of Massive Datasets](http://www.mmds.org/)，相关内容可以参考其PPT和讲义，非常详细。

### GBDT、XGBoost、LightGBM补充

- GBDT参考文献，[Greedy Function Approximation: A Gradient Boosting Machine](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)，[当我们在谈论GBDT：从 AdaBoost 到 Gradient Boosting](https://zhuanlan.zhihu.com/p/25096501)
- XGBoost参考文献，[XGBoost: A Scalable Tree Boosting System](http://cinslab.com/wp-content/uploads/2019/06/Ke-Wang-XGBoost-A-Scalable-Tree-Boosting-System.pdf)，[知乎问题，xgboost原理？](https://www.zhihu.com/question/58883125/answer/206813653)
- LightGBM参考文献，[LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)

### 题目回忆

这次考试总的来说还是有点意外的，没有想到真的考算法模拟，还考了3个。

根据题目顺序说一下：

1. 画ROC曲线
2. 解释交叉验证，Kfold和Statified Kflod的区别（后者为分层采样，脑抽写错了）
3. 学习器为树模型的时候，如何选择划分的特征
4. 举例说明，基于内容的推荐算法中，项模型和用户模型的区别
5. 推荐系统的冷启动问题，如何解决
6. 二分图匹配问题，模拟
7. 中介度算法模拟
8. 重采样算法中，解释ENN和CNN
9. GBDT、xgboost和LightGBM的区别。

**总的来说，这门课比较有用，建议修改为4.5分课程，推至大三春季学期学习，增加实验（比如后面的xgboost实践）。**
