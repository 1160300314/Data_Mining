# 基于模型的协同过滤算法的实现

## 基本要求

- 基于UV分解，建立协同过滤模型（矩阵分解的代码要自己编写）
- 在user_artist_data中，预留20%的数据，作为验证集
- 计算模型对验证集进行预测的结果的RMSE

## 数据集

数据集路径均为"`./*.txt`"

- `user_artist_data.txt`：2420万条用户播放艺术家歌曲次数
- `artist_data.txt`: 160+万个艺术家的ID和名字
- `artist_alias.txt`: 拼写错误的艺术家ID（变体）到该艺术家的规范ID的映射关系（19万条记录）

## 数据处理部分

相关的处理步骤见`./Data-Preprocessing.ipynb`, 此处仅仅说明一些处理的结果.

`./user_artist_data.txt`中包含2400余万条数据, 其正确的格式应该为`用户id 艺术家id 次数`.
可以使用shell脚本对数据进行处理, 主要利用`grep`命令来做. 经过判断可以发现全部的数据均符合要求.
**对于其余两个源数据文件也进行类似的处理, 此处不进行赘述**

对于已经得到格式正确的数据, 需要进行下面几个步骤的处理

1. 由于`./user_artist_data.txt`中存在部分错误的艺术家id, 所以首先利用`./artist_correct_format_alias.txt`中正确的艺术家id来进行替换
2. 得到正确处理过的M矩阵, 根据统计其中的最大/最小用户id和艺术家id, 发现其不是连续的, 而在U,V矩阵中如果能够利用连续的下标可以使得存储空间得到一定的节省, 所以利用python中的字典对数据建立id和下标的映射.
3. 每个id映射为下标后, 重新输出到文件中, 保存在`./out.txt`.

## 数据划分

主要利用了两种不同的方式, 进行数据划分, 划分数据为20%的测试数据, 剩余80%为训练数据.

1. 生成0-1之间的随机数, 当生成随机数小于0.2时, 将对应的数据划分到测试集, 否则划分到训练数据.
2. 由于第一种方式不能够保证每一个用户均出现在训练数据中(在我们随机进行的一次测试中, 这种性质得到的偶然得到了保证), 所以采取了对于每一个用户都随机选取其听歌数据的20%作为测试集.

使用第一种划分得到的训练和测试集保存在`./train.txt, test.txt`. 第二种的划分结果保存在`./train-split-user.txt, test-split-user.txt`.
划分的具体实现为`./split.py`.

## 矩阵分解部分

主要有以下几种不同的实现方式

1. 使用python实现PPT上公式所表示的矩阵分解
2. 使用C++实现PPT上公式所示的矩阵分解
3. 使用python实现基于GD的ALS
4. 使用C++实现基于GD的ALS
5. 使用python实现含有正则系数的ALS

### 关于第一种实现方式

首先基于这个方式的矩阵分解是最早实现的，但是由于其固有的复杂度过高和没有用到numpy等一些矩阵运算的加速工具，
导致每一轮的实际运行时间过长，所以没有实际运行的结果保留。

更新U矩阵中第r行,第s列位置的公式为:
$$
x=\frac{\sum_{j} v_{s j}\left(m_{r j}-\sum_{k \neq s} u_{r k} v_{k j}\right)}{\sum_{j} v_{s j}^{2}}
$$
更新V矩阵中第r行,第s列位置的公式为:
$$
y=\frac{\sum_{i} u_{i r}\left(m_{i s}-\sum_{k \neq r} u_{i k} v_{k s}\right)}{\sum_{i} u_{i r}^{2}}
$$

我们通过上面的公式,在U矩阵和V矩阵中交替地更新其中的元素,每当U和V矩阵全部更新完一次之后,计算此时训练集上的RMSE,
当迭代达到一定轮数或者两轮迭代RMSE的差值的绝对值小于某个阈值时,停止迭代.

源文件为`Lab-1.py`，主要函数为`UV_composition`，其用于矩阵分解的计算。

### 关于第二种方式

这种方式相比第一种方式，其主要的不同在于实现细节，我们使用C++代替了python, 并且增加了一个空间中的索引，用于记录两种信息：
该行有多少元素以及该列有多少元素。

具体的实现示例，`map<int, map<int, int> > M`, 我们存储了两个这样的数据结构: 

第一个`map<int, map<int, int> >`中, 外层map的key位置存储的是矩阵中元素的行, 内层map的key位置存储的是矩阵中元素的列, 
内层map的value位置存储的是矩阵中对应位置的元素值;

第二个`map<int, map<int, int> >`中, 外层map的key位置存储的是矩阵中元素的列, 内层map的key位置存储的是矩阵中元素的行, 
内层map的value位置存储的是矩阵中对应位置的元素值;

其实仅存储一个这样的`map<int, map<int, int> >`便可以实现所需要的功能, 存储两个其实是出于用空间换时间这样一个目的: 
更新U和V矩阵时, 我们需要代入第一种方式中提到的公式, 其中更新U矩阵中元素时, 我们需要在训练数据"矩阵"M中寻找某一行, 
而更新V矩阵中元素时, 我们需要在"矩阵"中寻找某一列, 所以我们采用了存储两个这样的 `map<int, map<int, int> >`, 来加速
更新U和V矩阵时对训练数据的查找过程.

**源文件为`als.cpp`。**
使用这种方式，对于训练集数据保持预期的结果，当调整参数d时，随着d的增大，对于矩阵M的拟合变好，
整体的RMSE下降；但对于测试数据，无论d取值如何，其RMSE都随着迭代的轮数而增大。

由于实验期间曾询问老师关于以上情况的问题，曾怀疑与训练集、测试集数据划分相关，改变了数据集划分
的方式之后，这种状况仍然没有改变。

### 关于第三种、第四种方式

这两种实现没有本质的区别，细节上也几乎相同，但由于“C++语言速度更快”的原因，在测试时选择了这种
实现方式进行。源文件为服务器上的`/UnderG/zhumingyan/DM/main.cpp`。

关于GD算法原理:

首先定义损失函数，这里使用训练数据矩阵M与重新构建的`UV`矩阵之间误差的平方作为损失函数：

$$e_{i j}^{2}=\left(r_{i j}-\hat{r}_{i j}\right)^{2}=\left(r_{i j}-\sum_{k=1}^{K} p_{i k} q_{k j}\right)$$

最终我们需要求解所有的非0项的损失函数之和的最小值：

$$
\min \operatorname{loss}=\sum_{r_{i j} \neq 0} e_{i j}^{2}
$$

对该损失函数的求解：对于上述的平方损失函数，我们通过梯度下降法求解，梯度下降法的核心步骤为：

1. 求解损失函数的负梯度：

$$
\begin{array}{l}{\frac{\partial}{\partial p_{i k}} e_{i j}^{2}=-2\left(r_{i j}-\sum_{k=1}^{K} p_{i k} q_{k j}\right) q_{k j}=-2 e_{i j} q_{k j}} \\ {\frac{\partial}{\partial q_{i k}} e_{i j}^{2}=-2\left(r_{i j}-\sum_{k=1}^{K} p_{i k} q_{k j}\right) p_{i k}=-2 e_{i j} p_{i k}^{j}}\end{array}
$$

2. 根据负梯度的方向更新变量：
  
$$
\begin{array}{l}{p_{i k}^{\prime}=p_{i k}-\alpha \frac{\partial}{\partial p_{i k}} e_{i j}^{2}-lamda*p_{i k}=p_{i k}+2 e_{i j} q_{k j}}-lamda*p_{i k} \\ {q_{k j}^{\prime}=q_{k j}-\alpha \frac{\partial}{\partial q_{k j}} e_{i j}^{2}-lamda*q_{k j}=q_{k j}+2 e_{i j} p_{i k}}-landa*q_{k j}\end{array}
$$

在实现时, 采用了和ALS相似的方式, 只不过是在每轮迭代更新U和V矩阵时, 有两点不同的地方: 

1. 在ALS中, 我们是根据U和V矩阵中的元素去训练数据中找某一行或某一列; 而在GD中, 我们是根据某条训练样本, 去寻找U矩阵中的一行以及V矩阵中的一列.
2. 第二点区别在于更新U和V矩阵时使用的公式不同.

在测试的时候，由于GD这种方式引入了更多的超参数，包括学习率(learning rate, lr)，正则项系数($\lambda$)，
所以需要更多的测试来观察实验结果。

学习率的大小会影响error的计算，进而影响U、V矩阵中的值，由于double数据的存储限制，lr的取值为1e-6，
当盲目调大lr时会导致double类型的上溢出。

整体的测试结果为，在训练集上RMSE始终呈现下降趋势，在测试集数据上RMSE则下降极慢，甚至会出现偶尔的波动上升情况。

```txt
Now d = 10
lamda = 0.1, lr = 1e-06
0 165.671, 85.6415
1 165.575, 85.4691
2 165.487, 85.3378
3 165.388, 85.2345
4 165.245, 85.1564
5 164.994, 85.1125
6 164.506, 85.1322
7 163.507, 85.2854
8 161.426, 85.7208
9 157.156, 86.7273
10 148.921, 88.771
11 135.303, 92.3097
12 118.714, 97.1482
13 104.28, 102.207
14 92.0621, 106.87
15 83.7025, 110.577
16 80.2615, 112.339
17 79.0701, 112.671
18 78.6039, 112.562
19 78.3895, 112.382
20 78.2653, 112.201
21 78.1743, 112.031
22 78.0963, 111.876
23 78.024, 111.735
24 77.9548, 111.609
25 77.8875, 111.496
26 77.8217, 111.396
27 77.7571, 111.308
28 77.6934, 111.232
29 77.6305, 111.167
30 77.5682, 111.112
31 77.5062, 111.066
32 77.4445, 111.03
33 77.3829, 111.002
34 77.3212, 110.983
35 77.2592, 110.971
36 77.1968, 110.967
37 77.1339, 110.97
38 77.0703, 110.979
39 77.0059, 110.996
40 76.9406, 111.018
41 76.8743, 111.047
42 76.8068, 111.082
43 76.7381, 111.122
44 76.6681, 111.168
45 76.5966, 111.219
46 76.5238, 111.276
47 76.4493, 111.337
48 76.3733, 111.402
49 76.2957, 111.473
50 76.2164, 111.547
51 76.1355, 111.625
52 76.0529, 111.706
53 75.9686, 111.791
54 75.8827, 111.879
55 75.7952, 111.969
56 75.7063, 112.062
57 75.6158, 112.156
58 75.5241, 112.252
59 75.4311, 112.349
60 75.3371, 112.447
61 75.2423, 112.546
62 75.1468, 112.644
63 75.0509, 112.743
64 74.9548, 112.841
65 74.8589, 112.938
66 74.7633, 113.034
67 74.6684, 113.13
68 74.5746, 113.224
69 74.482, 113.316
70 74.3911, 113.407
71 74.3019, 113.497
72 74.2149, 113.584
73 74.1301, 113.67
74 74.0478, 113.753
75 73.9681, 113.835
76 73.891, 113.915
77 73.8166, 113.993
78 73.7448, 114.07
79 73.6758, 114.144
80 73.6093, 114.217
81 73.5453, 114.288
82 73.4836, 114.357
83 73.4242, 114.425
84 73.367, 114.491
85 73.3117, 114.556
86 73.2582, 114.619
87 73.2064, 114.682
88 73.1563, 114.743
89 73.1075, 114.803
90 73.0601, 114.862
91 73.014, 114.92
92 72.9689, 114.978
93 72.925, 115.035
94 72.8819, 115.091
95 72.8398, 115.146
96 72.7986, 115.201
97 72.7581, 115.256
98 72.7184, 115.31
99 72.6793, 115.364
100 72.641, 115.417
101 72.6032, 115.471
102 72.5661, 115.524
103 72.5295, 115.577
104 72.4935, 115.63
105 72.4581, 115.684
106 72.4231, 115.737
107 72.3887, 115.79
108 72.3548, 115.843
109 72.3213, 115.897
110 72.2884, 115.951
111 72.2558, 116.005
112 72.2238, 116.059
113 72.1922, 116.113
114 72.161, 116.168
115 72.1302, 116.223
116 72.0999, 116.279
117 72.07, 116.335
118 72.0405, 116.391
119 72.0114, 116.448
120 71.9827, 116.505
121 71.9544, 116.562
122 71.9264, 116.621
123 71.8989, 116.679
124 71.8717, 116.738
125 71.8448, 116.798
126 71.8184, 116.858
127 71.7923, 116.919
128 71.7665, 116.98
129 71.741, 117.042
130 71.7159, 117.104
131 71.6912, 117.167
132 71.6667, 117.231
133 71.6426, 117.295
134 71.6188, 117.36
135 71.5953, 117.425
136 71.572, 117.491
137 71.5491, 117.558
138 71.5265, 117.625
139 71.5041, 117.693
140 71.482, 117.761
141 71.4602, 117.83
142 71.4387, 117.9
143 71.4174, 117.97
144 71.3964, 118.041
145 71.3756, 118.113
146 71.3551, 118.185
147 71.3348, 118.258
148 71.3147, 118.331
149 71.2949, 118.405
150 71.2752, 118.48
151 71.2559, 118.555
152 71.2367, 118.631
153 71.2177, 118.707
154 71.1989, 118.784
155 71.1804, 118.862
156 71.162, 118.94
157 71.1438, 119.019
158 71.1258, 119.098
159 71.108, 119.178
160 71.0904, 119.259
161 71.0729, 119.34
162 71.0556, 119.422
163 71.0385, 119.504
164 71.0216, 119.587
165 71.0048, 119.67
166 70.9881, 119.754
167 70.9716, 119.839
168 70.9553, 119.924
169 70.9391, 120.009
170 70.9231, 120.095
```

```txt
d = 15
Initial RSME: 165.588, 85.4828
1, Current RSME: 165.578, 85.47
2, Current RSME: 165.566, 85.4559
3, Current RSME: 165.551, 85.4408
4, Current RSME: 165.532, 85.4248
5, Current RSME: 165.506, 85.4077
6, Current RSME: 165.472, 85.39
7, Current RSME: 165.424, 85.3727
8, Current RSME: 165.358, 85.3594
9, Current RSME: 165.271, 85.3588
10, Current RSME: 165.165, 85.388
11, Current RSME: 165.055, 85.4651
12, Current RSME: 164.968, 85.5709
13, Current RSME: 164.919, 85.6353
14, Current RSME: 164.898, 85.6428
15, Current RSME: 164.888, 85.6314
16, Current RSME: 164.879, 85.6171
17, Current RSME: 164.872, 85.6025
18, Current RSME: 164.864, 85.5881
19, Current RSME: 164.856, 85.5738
20, Current RSME: 164.848, 85.5597
21, Current RSME: 164.84, 85.5457
22, Current RSME: 164.833, 85.5319
23, Current RSME: 164.825, 85.5183
24, Current RSME: 164.817, 85.5049
25, Current RSME: 164.81, 85.4917
26, Current RSME: 164.802, 85.4787
27, Current RSME: 164.795, 85.466
28, Current RSME: 164.787, 85.4534
29, Current RSME: 164.78, 85.4412
30, Current RSME: 164.773, 85.4292
31, Current RSME: 164.765, 85.4175
32, Current RSME: 164.758, 85.4062
33, Current RSME: 164.751, 85.3953
34, Current RSME: 164.744, 85.3848
35, Current RSME: 164.737, 85.3747
36, Current RSME: 164.731, 85.365
37, Current RSME: 164.724, 85.3558
38, Current RSME: 164.718, 85.3471
39, Current RSME: 164.712, 85.3388
40, Current RSME: 164.706, 85.3309
41, Current RSME: 164.7, 85.3234
42, Current RSME: 164.694, 85.3161
43, Current RSME: 164.689, 85.309
44, Current RSME: 164.683, 85.302
45, Current RSME: 164.678, 85.295
46, Current RSME: 164.673, 85.2878
47, Current RSME: 164.668, 85.2804
48, Current RSME: 164.663, 85.2728
49, Current RSME: 164.658, 85.2648
50, Current RSME: 164.653, 85.2566
51, Current RSME: 164.648, 85.248
52, Current RSME: 164.643, 85.2392
53, Current RSME: 164.639, 85.2302
54, Current RSME: 164.634, 85.2209
55, Current RSME: 164.629, 85.2115
56, Current RSME: 164.625, 85.202
57, Current RSME: 164.62, 85.1924
58, Current RSME: 164.616, 85.1828
59, Current RSME: 164.611, 85.1732
60, Current RSME: 164.607, 85.1636
61, Current RSME: 164.603, 85.1541
62, Current RSME: 164.599, 85.1447
63, Current RSME: 164.595, 85.1353
64, Current RSME: 164.591, 85.1261
65, Current RSME: 164.587, 85.117
66, Current RSME: 164.583, 85.1081
67, Current RSME: 164.58, 85.0993
68, Current RSME: 164.576, 85.0908
69, Current RSME: 164.573, 85.0823
70, Current RSME: 164.57, 85.0741
71, Current RSME: 164.567, 85.0662
72, Current RSME: 164.564, 85.0584
73, Current RSME: 164.561, 85.0508
74, Current RSME: 164.558, 85.0435
75, Current RSME: 164.556, 85.0364
76, Current RSME: 164.553, 85.0296
77, Current RSME: 164.551, 85.023
78, Current RSME: 164.548, 85.0167
79, Current RSME: 164.546, 85.0107
80, Current RSME: 164.544, 85.0049
81, Current RSME: 164.542, 84.9994
82, Current RSME: 164.54, 84.9941
83, Current RSME: 164.538, 84.9892
84, Current RSME: 164.537, 84.9844
85, Current RSME: 164.535, 84.98
86, Current RSME: 164.533, 84.9758
87, Current RSME: 164.532, 84.9719
88, Current RSME: 164.531, 84.9682
89, Current RSME: 164.529, 84.9647
90, Current RSME: 164.528, 84.9615
91, Current RSME: 164.527, 84.9586
92, Current RSME: 164.526, 84.9558
93, Current RSME: 164.525, 84.9533
94, Current RSME: 164.524, 84.951
95, Current RSME: 164.523, 84.9489
96, Current RSME: 164.522, 84.9471
97, Current RSME: 164.522, 84.9454
98, Current RSME: 164.521, 84.9439
99, Current RSME: 164.52, 84.9426
100, Current RSME: 164.52, 84.9415
101, Current RSME: 164.519, 84.9406
102, Current RSME: 164.519, 84.9399
103, Current RSME: 164.519, 84.9393
104, Current RSME: 164.518, 84.9389
105, Current RSME: 164.518, 84.9387
106, Current RSME: 164.518, 84.9386
107, Current RSME: 164.518, 84.9386
108, Current RSME: 164.518, 84.9389
109, Current RSME: 164.518, 84.9392
110, Current RSME: 164.518, 84.9397
111, Current RSME: 164.519, 84.9404
112, Current RSME: 164.519, 84.9412
113, Current RSME: 164.519, 84.9421
114, Current RSME: 164.52, 84.9432
115, Current RSME: 164.52, 84.9444
116, Current RSME: 164.52, 84.9457
117, Current RSME: 164.521, 84.9471
118, Current RSME: 164.522, 84.9487
119, Current RSME: 164.522, 84.9504
120, Current RSME: 164.523, 84.9522
121, Current RSME: 164.524, 84.9541
122, Current RSME: 164.525, 84.9562
123, Current RSME: 164.526, 84.9583
124, Current RSME: 164.526, 84.9606
125, Current RSME: 164.527, 84.963
126, Current RSME: 164.528, 84.9654
127, Current RSME: 164.53, 84.968
128, Current RSME: 164.531, 84.9707
129, Current RSME: 164.532, 84.9736
130, Current RSME: 164.533, 84.9765
```

### 关于第五种方式

参考[斯坦福大学2015春季cme323课程的第14次笔记][lec14]的基本实现。

相比第一和第二种方式中使用的矩阵元素更新公式，这里每次更新U矩阵的某一行，以及V矩阵的某一列，在时间复杂度上有了明显的下降，使用python编写，在合理的时间内可以迭代出结果。

算法原理如下：

在每一轮迭代过程中，U矩阵的某一行按下面的公式来更新： 

$$x_{u}=\left(\sum_{r_{\text {uit} \in r_{u *}}} y_{i} y_{i}^{\top}+\lambda I_{k}\right)^{-1} \sum_{r_{\text {ui} \in r_{u *}}} r_{u i} y_{i}$$

V矩阵的某一行按下面的公式来更新：
$$
y_{i}=\left(\sum_{r_{u i} \in r_{* i}} x_{u} x_{u}^{\top}+\lambda I_{k}\right)^{-1} \sum_{r_{u i} \in r_{* i}} r_{u i} x_{u}
$$

但是结果不好,在测试集没有明显的下降

```txt
d=100
0 133.95669451900892 214.60835579330566
1 32.38666553758585 249.8540892836887
2 21.161960066608096 246.6009345891535
3 17.841627924375267 247.47574867238697

d=10
0 134.18884671400633 214.75470196519635
1 59.95245583620546 226.71918232802616
2 50.92096887964785 232.5874459099517
3 48.82042479097178 231.60463355065926
4 47.8034908671602 233.94479608136393
5 47.15307718102269 237.8236481612709
6 46.677829585847675 242.26203729005348
7 46.31169250948892 246.9895694457516
```

[ lec14 ]: http://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf
[ fastals ]: https://web.stanford.edu/~rezab/papers/fastals.pdf

## 源文件介绍

- `./PPT-example.txt` : PPT上5x5的例子, 数据格式为`i,j,v`

## 参考文献

- [https://web.stanford.edu/~rezab/papers/fastals.pdf][ fastals ]
- [http://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf][ lec14 ]
